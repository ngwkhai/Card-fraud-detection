{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Đánh giá mô hình",
   "id": "8b2899ea9b8d98d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Import thư viện và đường đẫn",
   "id": "7a30477e6f59ed7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# Đường dẫn đến các mô hình đã lưu\n",
    "models_dir = \"../models\"\n",
    "model_files = [\"logistic_imbalance.pkl\", \n",
    "               \"decision_tree_imbalance.pkl\", \n",
    "               \"random_forest_imbalance.pkl\", \n",
    "               \"xgboost_imbalance.pkl\",\n",
    "               \"logistic_smote.pkl\", \n",
    "               \"decision_tree_smote.pkl\", \n",
    "               \"random_forest_smote.pkl\", \n",
    "               \"xgboost_smote.pkl\",\n",
    "               \"logistic_adasyn.pkl\", \n",
    "               \"decision_tree_adasyn.pkl\", \n",
    "               \"random_forest_adasyn.pkl\", \n",
    "               \"xgboost_adasyn.pkl\"]\n",
    "\n",
    "# Đường dẫn dữ liệu kiểm tra\n",
    "test_data_path = \"../data/splits/X_test.csv\"\n",
    "test_labels_path = \"../data/splits/y_test.csv\"\n",
    "\n",
    "figure_dir = \"../reports/figures\"\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Đọc tập dữ liệu và mô hình",
   "id": "5b62dd7f8d86548f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tạo dictionary để lưu các mô hình đã đọc\n",
    "models = {}\n",
    "\n",
    "# Đọc các mô hình\n",
    "for model_file in model_files:\n",
    "    model_path = os.path.join(models_dir, model_file)\n",
    "    if os.path.exists(model_path):\n",
    "        model_name = model_file.split(\".pkl\")[0]\n",
    "        models[model_name] = joblib.load(model_path)\n",
    "        print(f\"Đã tải mô hình: {model_name}\")\n",
    "    else:\n",
    "        print(f\"Mô hình không tồn tại: {model_path}\")\n",
    "\n",
    "# Đọc dữ liệu kiểm tra\n",
    "X_test = pd.read_csv(test_data_path)\n",
    "y_test = pd.read_csv(test_labels_path).values.ravel()\n"
   ],
   "id": "a96a9d6ce814e934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Tính toán các chỉ số đánh giá",
   "id": "c4a0d154c42c1f80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DataFrame để lưu kết quả đánh giá\n",
    "evaluation_results = pd.DataFrame()\n",
    "\n",
    "# Đánh giá từng mô hình\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Tính các chỉ số\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    # Lưu kết quả vào DataFrame\n",
    "    data_type = model_name.split(\"_\")[-1]  # imbalance, smote, adasyn\n",
    "    model_type = \"_\".join(model_name.split(\"_\")[:-1])  # logistic_regression, decision_tree, etc.\n",
    "    new_result = [model_type, data_type, accuracy, precision, recall, f1, roc_auc]\n",
    "    evaluation_results = pd.concat([evaluation_results, pd.DataFrame([new_result])], ignore_index=True)\n",
    "    \n",
    "evaluation_results.columns = [\"Model\", \"Data Type\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC-AUC\"]\n",
    "# Hiển thị kết quả\n",
    "print(evaluation_results)\n",
    " "
   ],
   "id": "15b0adb60a3a28fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Lưu các chỉ số đánh giá",
   "id": "268821d7b9b317e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Lưu bảng kết quả đánh giá ra tệp CSV\n",
    "evaluation_results.to_csv(\"../reports/tables/evaluation_results.csv\", index=False)\n"
   ],
   "id": "9d9712f9cfc8fcc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Vẽ các biểu đồ",
   "id": "a7fa8c0a3ce279df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Chuyển dữ liệu thành định dạng dài (long format)",
   "id": "30a2f5f80180828e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chuyển đổi dataframe sang định dạng dài\n",
    "evaluation_result_long = evaluation_results.melt(id_vars=['Model', 'Data Type'],\n",
    "                                                value_vars=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC'],\n",
    "                                                var_name='Metric',\n",
    "                                                value_name='Score')\n"
   ],
   "id": "1921a86226509dde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Vẽ biểu đồ cột so sánh các mô hình và các chỉ số",
   "id": "5c7607570134bbe5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Model', y='Score', hue='Metric', data=evaluation_result_long[evaluation_result_long['Data Type'] == 'imbalance'], ci=None)\n",
    "\n",
    "# Cài đặt tiêu đề và nhãn\n",
    "plt.title('So sánh hiệu suất mô hình trên các bộ dữ liệu imbalance')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Metrics\", loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figure_dir, \"15_comparison_imbalance.png\"))\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()\n"
   ],
   "id": "952ac7a178bbe4b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Vẽ biểu đồ cột so sánh các mô hình và các chỉ số\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Model', y='Score', hue='Metric', data=evaluation_result_long[evaluation_result_long['Data Type'] == 'smote'], ci=None)\n",
    "\n",
    "# Cài đặt tiêu đề và nhãn\n",
    "plt.title('So sánh hiệu suất mô hình trên các bộ dữ liệu smote')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Metrics\", loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figure_dir, \"16_comparison_smote.png\"))\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()\n"
   ],
   "id": "92bb6a323cf65903",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Vẽ biểu đồ cột so sánh các mô hình và các chỉ số\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Model', y='Score', hue='Metric', data=evaluation_result_long[evaluation_result_long['Data Type'] == 'adasyn'], ci=None)\n",
    "\n",
    "# Cài đặt tiêu đề và nhãn\n",
    "plt.title('So sánh hiệu suất mô hình trên các bộ dữ liệu adasyn')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Metrics\", loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(figure_dir, \"17_comparison_adasyn.png\"))\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()\n"
   ],
   "id": "b84db01039b153b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Vẽ biểu đồ ROC AUC",
   "id": "1c5ef481181bca1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_measure_model(models):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for name, model, X_test, y_test in models:\n",
    "        \n",
    "        # Predict\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # plot ROC Curve\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred)\n",
    "        auc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=name + \", auc=\" + str(auc))\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.plot([0, 1], [0, 1], 'k--' )\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('ROC curve for Predicting a credit card fraud detection')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    \n",
    "    # Lấy tên từ model đầu tiên\n",
    "    model_names = \"_\".join([name.split(\" \")[0] for name, _, _, _ in models])\n",
    "    save_path = os.path.join(figure_dir, f\"roc_curve_{model_names}.png\")\n",
    "    print(save_path)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ],
   "id": "9d8868dd4671342",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Vẽ cho Logistic regression",
   "id": "48fb29a465d7f39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LRmodels = [] #LogisticRegression model\n",
    "\n",
    "LRmodels.append(('LR imbalance', models[\"logistic_imbalance\"], X_test, y_test))\n",
    "LRmodels.append(('LR SMOTE', models[\"logistic_smote\"], X_test, y_test))\n",
    "LRmodels.append(('LR ADASYN', models[\"logistic_adasyn\"], X_test, y_test))\n",
    "\n",
    "build_measure_model(LRmodels)"
   ],
   "id": "d6eef96671ab980f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Vẽ cho Decision tree",
   "id": "4b3922a0b690e455"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DTmodels = [] #Decision Tree model\n",
    "\n",
    "DTmodels.append(('DT imbalance', models[\"decision_tree_imbalance\"], X_test, y_test))\n",
    "DTmodels.append(('DT SMOTE', models[\"decision_tree_smote\"], X_test, y_test))\n",
    "DTmodels.append(('DT ADASYN', models[\"decision_tree_adasyn\"], X_test, y_test))\n",
    "\n",
    "build_measure_model(DTmodels)"
   ],
   "id": "4a409d9e26c57595",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Vẽ cho Random forest",
   "id": "e65c0a1c892cfeea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RFmodels = [] #Random Forest model\n",
    "\n",
    "RFmodels.append(('RF imbalance', models[\"random_forest_imbalance\"],X_test,y_test))\n",
    "RFmodels.append(('RF SMOTE', models[\"random_forest_smote\"], X_test, y_test))\n",
    "RFmodels.append(('RF ADASYN', models[\"random_forest_adasyn\"], X_test, y_test))\n",
    "\n",
    "build_measure_model(RFmodels)"
   ],
   "id": "51e320b222a46976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Vẽ cho XGBoost ",
   "id": "befd99ed1283a24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "XGBmodels = [] #XGBoost model\n",
    "\n",
    "XGBmodels.append(('XGBoost imbalance', models[\"xgboost_imbalance\"], X_test, y_test))\n",
    "XGBmodels.append(('XGBoost SMOTE', models[\"xgboost_smote\"], X_test, y_test))\n",
    "XGBmodels.append(('XGBoost ADASYN', models[\"xgboost_adasyn\"], X_test, y_test))\n",
    "\n",
    "build_measure_model(XGBmodels)"
   ],
   "id": "ddbc0558847d4e82",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
